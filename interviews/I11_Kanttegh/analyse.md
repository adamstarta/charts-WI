# Interview-Analyse: I11 Singh Kanttegh

## 1. Kontext

**Interviewpartner:** Singh Kanttegh
**Persönlicher Hintergrund:** Verlust des Großvaters väterlicherseits, zu dem nur wenige Kindheitserinnerungen bestehen. Engste Beziehung zur Mutter.

**Besonderheit des Falls:** Der Interviewpartner hat eine verstorbene nahestehende Person (Großvater) verloren, allerdings ohne aktive Erinnerungen an diese Person. Die einzigen Erinnerungsanker sind digitalisierte Fotos aus der Kindheit. Dies prägt seine Perspektive auf digitale Erinnerungsformen und KI-basierte Nachlasskonzepte erheblich.

---

## 2. Forschungsfrage A: Mediennutzung und digitale Erinnerungsformen

### 2.1 Aktuelle digitale Erinnerungspraxis

**Verfügbare Erinnerungsformen:**
- Ursprünglich **ausgedruckte Fotos** des Großvaters, die mittlerweile **digitalisiert** wurden (gescannt)
- Keine Videos, keine Sprachnachrichten, keine Social Media Profile
- Nur visuelle Momentaufnahmen als Erinnerungsanker

**Emotionale Bedeutung:**
> "Es hat mir eine Freude bereitet, dass ich... dass er mich noch als Kind sehen konnte und ich ihn auch, selbst wenn ich keine Erinnerung mehr habe."

Die Fotos erfüllen eine kompensatorische Funktion: Sie ersetzen fehlende Erinnerungen und schaffen einen Beweis für eine Beziehung, die emotional nicht mehr greifbar ist.

### 2.2 Hierarchie der Erinnerungsformen

**Wichtigste Form: Gemeinsame Fotos**
> "Ich hab schon Fotos von ihm gesehen, wo er noch lebendig war. Aber das Foto von uns beiden auf einem Bild ist noch schon noch etwas wie persönlich oder eine bessere, bessere Bindung."

**Rangfolge der emotionalen Wirkung:**
1. **Gemeinsame Fotos** (Kanttegh + Großvater) → höchste emotionale Bindung
2. **Fotos/Videos der Person allein** → positive Emotionen, aber geringere persönliche Verbindung
3. **Keine Präferenz zwischen Fotos und Videos** → beide Medien lösen gleiche Emotionen aus

**Zentrale Aussage:**
> "Fotos lösen und Videos lösen, glaub die meisten Emotionen aus. Halt keine traurigen, weil halt eben keine Erinnerung, aber ich würd sagen, Fotos lösen die besten Emotionen aus."

### 2.3 Keine Kommunikation mit dem Verstorbenen

Auf die Frage, ob er beim Betrachten digitaler Spuren das Gefühl hatte, mit der verstorbenen Person zu kommunizieren, antwortet Kanttegh klar: **"Nein."**

Dies ist bedeutsam, da es zeigt, dass digitale Erinnerungsformen für ihn rein retrospektiv funktionieren - nicht interaktiv oder kommunikativ.

### 2.4 Bewusstsein über digitalen Nachlass

> "Ich hab nie über über das nachgedacht. Also, es war mir nie wie bewusst, dass man, dass Fotos immer noch ein digitaler Nachweis Nachlass sind. Das ist immer noch alles digital."

**Reflexion zur digitalen Transformation:**
- Früher: ausgedruckte Fotos als physische Erinnerungsobjekte
- Heute: alles digital im Handy gespeichert
- Bewusstsein, dass die Materialisierung von Erinnerungen sich grundlegend gewandelt hat

### 2.5 Präferenzen für den eigenen digitalen Nachlass

**Klare Ablehnung KI-basierter Inhalte:**
> "Ich will wollen, dass es nichts von mir KI-basiert gibt, sondern nur die Momente, die wirklich passiert sind. Aufgenommen von meiner Kamera, sei es Handy, Digitalkamera, whatever. Aber Leute sollen sich an Fotos und Videos festhalten, wenn sie das wollen, aber es soll von mir nichts KI-basiertes geben."

**Präferierte Formate für den eigenen Nachlass:**
1. **Sprachmemos** (selbst aufgenommen, falls möglich)
2. **Fotos und Videos** (echte Aufnahmen)
3. **Dokumente** (für Wissensweitergabe)
4. **Videoaufnahmen** (wie in "Blacklist" - zur Wissensvermittlung)

**Bedingung für technologisch fortgeschrittene Formen:**
> "So hologram mäßig also in VR. Finde ich, würde nur Sinn machen, wenn es eine Echtaufnahme ist der Person... keine KI-basierte Aufnahme."

Selbst bei VR-Avataren oder Hologrammen: **Authentizität geht vor Technologie.**

---

## 3. Forschungsfrage B: KI-Nachlass vs. Klassische Erinnerungen

### 3.1 Erste Reaktion auf KI-Chatbot-Konzept

**Spontane Reaktion: Kritisch**
> "Kritisch. Also, es könnte halt relativ triggern. Also, ich meine persönliche Reaktion wär drauf, da ich, da ich eben keine Erinnerung habe, wär es vielleicht im ersten Moment Schön. Ähm, aber weil die Klasse die auch so, ja, es ist nicht ganz das Gleiche, weil es dann immer noch K.I. ist."

**Ambivalenz bei geringer emotionaler Bindung:**
- Im Fall des Großvaters (keine aktiven Erinnerungen): könnte im ersten Moment schön sein
- Aber: grundsätzliche Skepsis, da "es immer noch KI ist"
- Bewusstsein für das Triggerpotenzial bei anderen Menschen

> "Es kann jetzt nicht von mir reden. Mich würde das jetzt nicht verstören oder so, aber es gibt sicher Leute, die könnte das verstören."

### 3.2 Ablehnung bei starker emotionaler Bindung

**Szenario: KI-Chatbot der Mutter**

**Kategorische Ablehnung:**
> "Ähm, da das würde ich nicht machen, weil es ist halt immer noch KI und ich... Also ja, seit seit ich geboren bin, bin ich bei meiner Mutter und da hab ich auch aktive Erinnerungen. Da machen die Erinnerungen halt schon etwas aus und das würde ich nicht wollen."

**Begründung: Emotionaler Schmerz**
> "Das würde nur schmerzen, auch wenn vielleicht die Stimme 1 zu 1 da ist, aber es ist sie ist nicht hier, ist nicht das Gleiche. Also, es würde mich definitiv mitnehmen. Ich will das nicht wollen."

**Kernaussage:**
> "Sie hat jetzt also... sie ist nicht mehr hier und fertig ist. Und wenn ich Rate brauche, gehe ich nicht. Es ist immer noch ein KI-Bot, schlussendlich so."

**Eindeutigkeit der Ablehnung:**
- "Unter allen Umständen gar nicht denkbar"
- "Nein." (auf die Frage, ob es eine Chance gäbe)

### 3.3 Fehlende Vorteile des KI-Nachlasses

**Persönliche Sicht: Keine Vorteile**
> "Nein, ich sehe da gar keine Vorteile, weil ich denk mir halt, der KI-Bot könnte die die Art von Erinnerung beziehungsweise die Art von, wie meine Mutter einfach alles gemacht hat, geredet, Sachen erledigt, was auch immer... Ist auch ne ne bestimmte Art dahinter."

**Zentrales Argument: Die "Art" ist entscheidend**
> "Und die könnten Kaibo Kaiboot könnte zwar die gleichen Aussagen tätigen, aber nicht mit dieser Art und es ist die Art, die es halt ausmacht. Und das könnt ihr in Kayboard nicht nachstellen. Deswegen, egal was, ich will da keinen Vorteil sehen."

**Philosophische Dimension:**
- Ein KI-Bot kann Inhalte reproduzieren
- Aber die **einzigartige "Art"** einer Person - ihr Wesen, ihre Ausstrahlung, ihre individuelle Ausdrucksweise - ist nicht reproduzierbar
- Diese "Art" ist das Wesentliche einer Person und ihrer Erinnerung

### 3.4 Potenzielle Vorteile für andere

Trotz persönlicher Ablehnung zeigt Kanttegh Verständnis für andere Nutzungsszenarien:

**Bedingung: Gesunde Trauerbewältigung**
> "Ist halt wie gut hast du den Tod verarbeitet? Ich find solange es sich nicht emotional wieder zurücksetzt an diesem Punkt, über den du hinweggekommen bist, kann man es machen, wenn es einem gut tut."

**Grenzen der Nutzung:**
> "Solang man sich halt nicht wirklich einfach nur auf das verlässt, für jede Situation, die man mit dieser Person erlebt hatte, finde ich es noch fair, aber eben solange man es nicht wie ausnutzt oder zu sehr benutzt, um im Leben voranzukommen."

**Zusammenfassung der Bedingungen:**
1. Emotionale Stabilität erreicht
2. Keine emotionale Abhängigkeit vom KI-Agent
3. Kein Ersatz für reales Leben
4. Kein Missbrauch zur Lebensbewältigung

### 3.5 Risiken und Bedenken

**1. Behinderung der Trauerbewältigung**
> "Dass man die quasi im Leben nicht vorankommt, weil man halt an diese Person immer noch festhält."

**2. Missbrauch als emotionale Waffe**
> "Eine emotionale Waffe mäßig. So, wenn jemand ähm. Sagen wir, du hast Streit mit deinem Partner... und diese benutzt einfach einen K.I. Agenten, um die Stimme, keine Ahnung, einer deiner naheliegenden, jetzt in diesem Fall, nehmen wir mal die Mutter, nachzumachen, um an sein Ziel zu gelangen durch den K.I. Bot."

**Konkrete Missbrauchsszenarien:**
- Manipulation durch Nachahmung der Stimme verstorbener Angehöriger
- Emotionale Erpressung in Konfliktsituationen
- Ausnutzung der emotionalen Verbindung

**3. Deepfakes und Täuschung**
> "Ich denke, dass die Stimme wird auch leicht. Ja, so ich hab's Deepfix, dass ihr dass die Stimme klonen könnt von irgendjemanden. Das ist schon mal gegeben und ich glaube, wenn so was so ein Chatbot rauskommen würde, würde das auch missbraucht werden."

**4. Datenschutz und Privatsphäre**
> "Was passiert denn, wenn die ganzen Daten geklaut werden und wird die Identität gestohlen und dann kannst du bist du selber gefakt. Dann gibt es zwei, zwei von deiner Person. Das ist halt auch noch das Risiko."

**Risiko-Hierarchie:**
1. Identitätsdiebstahl und Fälschung der eigenen Person
2. Emotionale Manipulation und Missbrauch
3. Behinderung der Trauerbewältigung
4. Abhängigkeit und Rückschritt in der persönlichen Entwicklung

### 3.6 Vergleich: KI vs. Klassische Erinnerungen

**Klassische digitale Erinnerungen (Fotos/Videos):**
- Authentisch und real
- Konservieren tatsächliche Momente
- Lösen positive Emotionen aus
- Keine Täuschung oder Illusion
- Statisch, aber wahrhaftig

**KI-basierte Nachlasse:**
- Künstlich und simuliert
- Können die "Art" der Person nicht reproduzieren
- Potenziell emotional schmerzhaft
- Risiko der Manipulation
- Interaktiv, aber nicht authentisch

**Zentraler Konflikt:**
> "Findet ihr auch, die Authentizität sollte einfach immer noch da sein, auch wenn es in der Technikwelt ist."

---

## 4. Forschungsfrage C: Authentizität, Grenzen, Kontrolle

### 4.1 Authentizität als höchster Wert

**Grundprinzip:**
> "Findet ihr auch, die Authentizität sollte einfach immer noch da sein, auch wenn es in der Technikwelt ist."

> "Ja, definitiv so, weil schlussendlich ist es immer noch authentisch genug und nicht von KI."

**Definition von Authentizität bei Kanttegh:**
1. **Echtaufnahmen** vs. KI-generierte Inhalte
2. **Reale Momente** vs. simulierte Interaktionen
3. **Tatsächliche Aufzeichnungen** vs. algorithmen-basierte Rekonstruktionen

**Konsistente Position:**
> "Hundertprozentig, ja, alles nur Echtaufnahmen von mir selber... Sollte nichts Theoretisch, nichts Fiktives sein, sondern wirklich eine Echtaufnahme."

### 4.2 Grenzen der Technologie

**4.2.1 Was Technologie NICHT kann**

**Die "Art" der Person:**
> "Der KI-Bot könnte die die Art von Erinnerung beziehungsweise die Art von, wie meine Mutter einfach alles gemacht hat, geredet, Sachen erledigt, was auch immer... Ist auch ne ne bestimmte Art dahinter. Und die könnten Kaibo Kaiboot könnte zwar die gleichen Aussagen tätigen, aber nicht mit dieser Art und es ist die Art, die es halt ausmacht."

**Physische Präsenz:**
> "Auch wenn vielleicht die Stimme 1 zu 1 da ist, aber es ist sie ist nicht hier, ist nicht das Gleiche."

**Emotionale Echtheit:**
> "Es ist halt immer noch KI... Es kann jetzt nicht von mir reden."

**4.2.2 Grenzen der Akzeptanz bei verschiedenen Technologien**

**VR/Hologramme: Bedingt akzeptabel**
> "So hologram mäßig also in VR. Finde ich, würde nur Sinn machen, wenn es eine Echtaufnahme ist der Person... keine KI-basierte Aufnahme... solange es eine Echtaufnahme ist... Und nicht irgendwas von Kaya erzeugt."

**Roboter: Abgelehnt**
> "Roboter ist eh alles KI-gesteuert"

**Chatbots: Kategorisch abgelehnt**
- Bei nahestehenden Personen: "unter allen Umständen gar nicht denkbar"

**Klonierte Stimmen/Deepfakes: Höchste Besorgnis**
- Risiko der Manipulation
- Identitätsdiebstahl
- Missbrauch für emotionale Erpressung

### 4.3 Kontrollaspekte

**4.3.1 Kontrolle über den eigenen Nachlass**

**Klare Vorgaben für den eigenen digitalen Nachlass:**
> "Ich will wollen, dass es nichts von mir KI-basiert gibt, sondern nur die Momente, die wirklich passiert sind."

**Selbstbestimmung über die Darstellung:**
- Nur selbst aufgenommene Sprachmemos
- Nur echte Fotos und Videos
- Nur tatsächlich existierende Dokumente
- Keine KI-Generierung

**4.3.2 Sorge um Kontrollverlust**

**Datenmissbrauch:**
> "Was passiert denn, wenn die ganzen Daten geklaut werden und wird die Identität gestohlen und dann kannst du bist du selber gefakt. Dann gibt es zwei, zwei von deiner Person."

**Unkontrollierte Nutzung durch Dritte:**
> "Sagen wir, du hast Streit mit deinem Partner... und diese benutzt einfach einen K.I. Agenten, um die Stimme... nachzumachen, um an sein Ziel zu gelangen."

**Verbreitung ohne Einwilligung:**
> "Ich denke, dass die Stimme wird auch leicht... geklont... ich glaube, wenn so was so ein Chatbot rauskommen würde, würde das auch missbraucht werden."

**4.3.3 Wer sollte Zugang haben?**

**Konzept des "Testaments" für KI-Nachlass:**
> "Ja, du kannst halt auch vorher ein Testament aufsetzen und sagen: 'Okay, diese Personen dürfen auf mich zugreifen und diese nicht.'"

**Vorsicht bei der Zugangskontrolle:**
> "Ja, aber ob du denen vertrauen kannst? Es ist so, also die könnten es ja, die könnten es ja, ich weiß nicht, missbrauchen und dann wer weiß was machen mit denen, Daten."

**Grundsätzliche Skepsis:**
- Testament ist theoretisch möglich
- Aber: Vertrauen schwierig
- Risiko des Missbrauchs bleibt bestehen

**4.3.4 Institutionelle Kontrolle**

**Skepsis gegenüber Unternehmen:**
> "Denke, es kommt drauf an, von welchem Unternehmen. Das ist, aber mir ist jetzt keines bekannt, dem ich so sehr vertrauen würde... Nein, also definitiv nicht Meta."

**Vertrauen in Tech-Unternehmen:**
- Kein ausreichendes Vertrauen in bekannte Unternehmen
- Meta explizit ausgeschlossen
- Generelle Skepsis gegenüber kommerzieller Verwaltung persönlicher Daten

**Idealvorstellung: Dezentrale Kontrolle**
> "Ideal wäre eigentlich, denk ich mal, wenn du einen eigenen Server hast. Der lokal bei dir ist... Ich würde es halt von mir rein lokal machen auf einem eigenen, was ganz separiert ist vom Internet."

**Technische Präferenz:**
- Eigener, lokaler Server
- Vollständige Trennung vom Internet
- Maximale Selbstkontrolle über die Daten

### 4.4 Ethische Grenzen

**4.4.1 Grenze zwischen Erinnerung und Täuschung**

**Simulation vs. Realität:**
> "Es ist halt immer noch KI... sie ist nicht hier, ist nicht das Gleiche."

Die zentrale ethische Grenze liegt für Kanttegh in der **Täuschung**: Ein KI-Agent simuliert Präsenz, wo keine ist. Dies wird als fundamentale Grenzüberschreitung empfunden.

**4.4.2 Würde der Verstorbenen**

**Respekt vor der Person:**
> "Es kann jetzt nicht von mir reden."

Die Vorstellung, dass eine KI "für" eine verstorbene Person sprechen könnte, verletzt für Kanttegh die Würde des Verstorbenen. Die Person kann sich nicht mehr äußern - also sollte auch keine KI in ihrem Namen sprechen.

**4.4.3 Recht auf digitale Selbstbestimmung**

**Zu Lebzeiten:**
> "Ich will wollen, dass es nichts von mir KI-basiert gibt."

**Nach dem Tod:**
Klare Erwartung, dass diese Wünsche respektiert werden sollten, auch wenn Vertrauen in die Umsetzung begrenzt ist.

### 4.5 Gesellschaftliche Grenzen

**4.5.1 Missbrauchspotenzial**

**Emotionale Manipulation:**
- Verwendung in Konflikten
- Nachahmung verstorbener Angehöriger zur Durchsetzung eigener Ziele
- Ausnutzung emotionaler Bindungen

**Identitätsdiebstahl:**
> "Was passiert denn, wenn die ganzen Daten geklaut werden und wird die Identität gestohlen und dann... gibt es zwei, zwei von deiner Person."

**Kommerzielle Ausbeutung:**
Sorge vor der Nutzung durch Unternehmen ohne angemessene Kontrolle oder Schutz.

**4.5.2 Regulierungsbedarf**

**Implizite Forderung nach Schutz:**
- Testament-Regelungen für KI-Nachlass
- Datenschutz und Datensicherheit
- Schutz vor Missbrauch
- Kontrolle über Zugriff und Nutzung

**Skepsis gegenüber Umsetzbarkeit:**
Trotz theoretischer Möglichkeiten (Testament, Zugriffskontrolle) bleibt Kanttegh skeptisch, ob ausreichender Schutz tatsächlich gewährleistet werden kann.

---

## 5. Zusammenfassung und Fazit

### 5.1 Kurzfazit

Singh Kanttegh repräsentiert einen **authentizitätsorientierten Skeptiker** im Diskurs um KI-basierte digitale Nachlässe. Seine Position ist geprägt von:

1. **Absoluter Priorität der Authentizität**: Nur echte Aufnahmen und reale Momente sind akzeptable Formen der Erinnerung
2. **Kategorischer Ablehnung von KI-Simulation**: Insbesondere bei nahestehenden Personen mit aktiven Erinnerungen
3. **Nuanciertem Risikobewusstsein**: Detaillierte Wahrnehmung von Missbrauchspotenzialen (emotionale Manipulation, Identitätsdiebstahl, Behinderung der Trauerbewältigung)
4. **Philosophischer Argumentation**: Die "Art" einer Person - ihr Wesen, ihre einzigartige Ausstrahlung - ist nicht reproduzierbar

Seine Ablehnung ist nicht technologiefeindlich, sondern basiert auf einem tiefen Verständnis der **ontologischen Differenz** zwischen Simulation und Realität. Kanttegh akzeptiert technologische Erinnerungsformen (digitalisierte Fotos, Videos, VR), solange sie auf **realen Aufnahmen** basieren.

### 5.2 Fazit-Tabelle

| Dimension | Position | Zentrale Argumente | Besonderheiten |
|-----------|----------|-------------------|----------------|
| **Aktuelle digitale Erinnerungen** | Positiv | - Digitalisierte Fotos als wichtigste Erinnerungsform<br>- Gemeinsame Fotos emotional bedeutsamer<br>- Fotos/Videos lösen positive Emotionen aus | - Keine aktiven Erinnerungen an Verstorbenen<br>- Fotos kompensieren fehlende Erinnerung<br>- Keine Kommunikation mit Verstorbenen |
| **KI-Chatbot (geringer emotionaler Bindung)** | Ambivalent-kritisch | - Könnte im ersten Moment "schön" sein<br>- Aber: "immer noch KI"<br>- Triggerpotenzial für andere | - Theoretisch offen, aber grundsätzlich skeptisch |
| **KI-Chatbot (starker emotionaler Bindung)** | Kategorisch ablehnend | - "Würde nur schmerzen"<br>- "Sie ist nicht hier, ist nicht das Gleiche"<br>- "Unter allen Umständen nicht denkbar" | - Klarste Position im gesamten Interview<br>- Emotional begründete Ablehnung |
| **Vorteile des KI-Nachlasses** | Persönlich: keine<br>Für andere: bedingt | - Keine persönlichen Vorteile sichtbar<br>- Für andere: nur bei gesunder Trauerbewältigung<br>- Bedingung: kein Ersatz für reales Leben | - Differenzierte Betrachtung für verschiedene Personengruppen |
| **Risiken** | Sehr hoch | - Behinderung der Trauerbewältigung<br>- Emotionale Manipulation<br>- Identitätsdiebstahl<br>- Deepfakes und Missbrauch | - Detaillierte und realistische Risikoanalyse<br>- Konkrete Missbrauchsszenarien |
| **Authentizität** | Höchster Wert | - "Authentizität sollte immer da sein"<br>- Nur "Echtaufnahmen", nichts Generiertes<br>- Die "Art" der Person ist nicht reproduzierbar | - Konsistentes Prinzip über alle Technologien<br>- Philosophisch fundierte Position |
| **Technologische Grenzen** | Klar definiert | - KI kann "Art" der Person nicht nachstellen<br>- Stimme ≠ Präsenz<br>- Inhalt ≠ Wesen | - Tiefes Verständnis der ontologischen Differenz |
| **Kontrolle (eigener Nachlass)** | Maximale Selbstbestimmung | - Nur selbstbestimmte Aufnahmen<br>- Keine KI-Generierung<br>- Klare Vorgaben für Hinterbliebene | - Sehr bewusste Nachlassplanung |
| **Kontrolle (Datensicherheit)** | Hohe Skepsis | - Misstrauen gegenüber Unternehmen<br>- Präferenz: lokaler Server, offline<br>- Sorge vor Missbrauch | - Pragmatischer Ansatz: technische Selbsthilfe |
| **Zugriffskontrolle** | Theoretisch möglich, praktisch skeptisch | - Testament-Regelung theoretisch sinnvoll<br>- Aber: Vertrauen schwierig<br>- Missbrauchsrisiko bleibt | - Realistische Einschätzung der Grenzen |
| **Ethische Grenzen** | Strikt | - KI kann nicht "für" Person sprechen<br>- Simulation = Täuschung<br>- Würde der Verstorbenen | - Prinzipiengeleitete ethische Position |
| **VR/Hologramme** | Bedingt akzeptabel | - Nur bei Echtaufnahmen als Basis<br>- Nicht KI-generiert | - Technologieoffen, aber mit klaren Bedingungen |
| **Regulierungsbedarf** | Implizit hoch | - Schutz vor Missbrauch notwendig<br>- Datenschutz zentral<br>- Rechtliche Rahmenbedingungen | - Keine expliziten Forderungen, aber implizite Notwendigkeit |

### 5.3 Theoretische Einordnung

**Kanttegh's Position im Spektrum der Akzeptanz:**

```
[Vollständige Ablehnung] ←─────── Kanttegh ─────────→ [Vollständige Akzeptanz]
                          ↑
                    Hier positioniert
              (Authentizitäts-orientierter Skeptiker)
```

**Charakteristische Merkmale:**
- **Nicht technologiefeindlich**, aber prinzipiengeleitet
- **Differenzierte Ablehnung**: Unterscheidung zwischen Echtaufnahmen-basierten und KI-generierten Formen
- **Konsistente Argumentation**: Authentizität als roter Faden durch alle Dimensionen

### 5.4 Zentrale Erkenntnis

Das Interview mit Kanttegh offenbart eine **fundamentale ontologische Kritik** an KI-basierten Nachlässen:

> **Die "Art" einer Person - ihr Wesen, ihre einzigartige Ausdrucksweise, ihre Präsenz - ist nicht algorithmisch reproduzierbar.**

Diese Position geht über pragmatische oder emotionale Bedenken hinaus und formuliert eine **philosophische Grenze** der Technologie: KI kann Inhalte simulieren, aber nicht das **Sein** einer Person erfassen.

### 5.5 Implikationen für die Thesis

**1. Authentizität als zentrale Akzeptanzdimension**
- Nutzer unterscheiden scharf zwischen "echt" und "generiert"
- Selbst perfekte Simulation wird als fundamental defizitär empfunden
- Authentizität ist wichtiger als Interaktivität

**2. Emotionale Nähe als Akzeptanzbarriere**
- Paradox: Je bedeutsamer die Beziehung, desto größer die Ablehnung
- Bei geringer emotionaler Bindung: Offenheit möglich
- Bei starker Bindung: Kategorische Ablehnung

**3. Missbrauchspotenzial als zentrales Hindernis**
- Konkrete, realistische Sorgen (nicht abstrakte Ängste)
- Emotionale Manipulation als greifbares Risiko
- Identitätsdiebstahl als existenzielle Bedrohung

**4. Kontrolle als Voraussetzung**
- Maximale Selbstbestimmung über eigenen Nachlass
- Skepsis gegenüber institutioneller Kontrolle
- Technische Selbsthilfe als bevorzugte Lösung

**5. Ethische Grenzen der Simulation**
- Würde der Verstorbenen nicht verhandelbar
- Simulation als Form der Täuschung
- "Für jemanden sprechen" als Grenzüberschreitung

**6. Differenzierte Technologieakzeptanz**
- Nicht generell technikskeptisch
- Akzeptanz abhängig von Authentizitätskriterium
- Technologie als Werkzeug, nicht als Ersatz

### 5.6 Forschungsrelevante Zitate

**Zur Authentizität:**
> "Findet ihr auch, die Authentizität sollte einfach immer noch da sein, auch wenn es in der Technikwelt ist."

**Zur ontologischen Grenze:**
> "Der KI-Bot könnte zwar die gleichen Aussagen tätigen, aber nicht mit dieser Art und es ist die Art, die es halt ausmacht. Und das könnt ihr in Kayboard nicht nachstellen."

**Zur emotionalen Realität:**
> "Das würde nur schmerzen, auch wenn vielleicht die Stimme 1 zu 1 da ist, aber es ist sie ist nicht hier, ist nicht das Gleiche."

**Zur Selbstbestimmung:**
> "Ich will wollen, dass es nichts von mir KI-basiert gibt, sondern nur die Momente, die wirklich passiert sind."

---

## Anhang: Methodische Anmerkungen

**Anzahl ausgewerteter Segmente:**
- Forschungsfrage A (Mediennutzung): 31 Segmente
- Forschungsfrage B (KI vs. Klassische Erinnerungen): 71 Segmente
- Forschungsfrage C (Authentizität, Grenzen, Kontrolle): 71 Segmente

**Besonderheiten des Interviews:**
- Hohe Konsistenz in der Argumentation
- Klare Prinzipienorientierung
- Differenzierte Betrachtung verschiedener Szenarien
- Philosophische Tiefe in der Begründung

**Repräsentativität:**
Kanttegh repräsentiert einen spezifischen Typus: den authentizitätsorientierten Skeptiker mit tiefem Technologieverständnis. Seine Position ist besonders wertvoll für die Analyse der **prinzipiellen Grenzen** von KI-basierten Nachlässen.
